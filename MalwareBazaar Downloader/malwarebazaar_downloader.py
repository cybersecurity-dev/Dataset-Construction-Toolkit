import requests
import sys
import argparse
import json
#import pyzipper
import os
import time
import requests
import zipfile
import pandas as pd

from os.path import exists
import pickle
from pathlib import Path
import csv


def print_column_counts(df):
    print("Column Counts:", len(df.columns))


def print_row_counts(df):
    print("Row Counts:", len(df.index))


def url_download_and_save_zip(url, filename):
  response = requests.get(url, stream=True)
  if response.status_code == 200:
    with open(filename, 'wb') as f:
      for chunk in response.iter_content(chunk_size=1024):
        if chunk:
          f.write(chunk)
    print(f"Downloaded and saved as {filename}")
  else:
    print(f"Failed to download: {response.status_code}")


def extract_downloaded_zip(zip_file_path, destination_folder):
  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(destination_folder)
  print(f"Extracted to {destination_folder}")


def skip_first_n_rows_and_import_csv(csv_file, n):
    tmp_file = 'tmp.csv'
    with open(csv_file, 'r') as infile, open(tmp_file, 'w', newline='') as outfile:
        reader = csv.reader(infile)
        writer = csv.writer(outfile)

        # Skip the first n rows
        for _ in range(n):
            next(reader)

        # Write the remaining rows to the output file
        writer.writerows(reader)
    df = pd.read_csv(tmp_file, encoding='utf-8', on_bad_lines='skip')
    return df.iloc[:-1]


def write_dataframe_to_pkl(df, fname):
    filename = fname + ".pkl"
    file_exists = exists(filename)
    if not file_exists:
        print("File not exist!..")
        df.to_pickle(filename) # save
    else:
        print("File exist!..")
        #rawdata = pd.read_pickle(filename) # load


def make_df_unique(df):
    nunique = df.nunique()
    cols_to_drop = nunique[nunique == 1].index
    df_dropcolumn = df.drop(cols_to_drop, axis=1)
    df_dropcolumn_droprow = df_dropcolumn.drop_duplicates()
    df_dropcolumn_droprow = df_dropcolumn_droprow.reset_index(drop=True)
    df_dropcolumn_droprow['file_type_guess'].value_counts()
    return df_dropcolumn_droprow


def delete_file(filename):
    #print(filename)
    if os.path.exists(filename) and not os.path.isdir(filename) and not os.path.islink(filename):
        os.remove(filename)
        print("Deleted File Name:" + filename)


def get_file(headers, zip_password, file_hash_name, will_unzip, zip_file_location, unzip_file_location):
    data = {
        'query': 'get_file',
        'sha256_hash': file_hash_name,
    }
    response = requests.post('https://mb-api.abuse.ch/api/v1/', data=data, timeout=15, headers=headers, allow_redirects=True)
    if 'file_not_found' in response.text:
        print("Error: file not found")
        sys.exit()
    else:
        zip_file_full_name = zip_file_location + file_hash_name + '.zip'
        open(zip_file_full_name, 'wb').write(response.content)

        if(will_unzip == True):
            try:
                with pyzipper.AESZipFile(zip_file_location + file_hash_name + '.zip') as zf:
                    zf.pwd = zip_password
                    my_secrets = zf.extractall(unzip_file_location)
                    print(f"{file_hash_name} is downloaded and unzipped.")
            except:
                print(f"File extraction error:{zip_file_full_name}")
                time.sleep(59)
                delete_file(zip_file_location + file_hash_name)
                delete_file(unzip_file_location + file_hash_name)
        else:
            print(f"{file_hash_name} is just downloaded.")


def is_zip_file_exist(filename, zip_file_location):
    if Path(zip_file_location + filename + ".zip").is_file():
        return True
    else:
        return False


def extract_zip(zip_file_path, destination_folder):
  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(destination_folder)
  print(f"Extracted to {destination_folder}")


def download_samples(df_malwarebazaar, filetype, dwn_file_location, unzip_file_location, will_unzip, headers, zip_password, total_samples = 0):
    df_malwarebazaar_uniq = make_df_unique(df_malwarebazaar)
    df_filtered_type = df_malwarebazaar_uniq[df_malwarebazaar_uniq["file_type_guess"].str.contains(filetype)]

    df_filtered_type['file_type_guess'].value_counts()
    df_file_hash = df_filtered_type['sha256_hash']

    index = 1
    for columnName, file_hash in df_file_hash.items():
        file_hash = file_hash[2:-1]
        #print(file_hash)
        if is_zip_file_exist(file_hash, dwn_file_location):
            continue
        else:
            get_file(headers, zip_password, file_hash, will_unzip, dwn_file_location, unzip_file_location)
            time.sleep(5)
        if index == total_samples:
            break
        index += 1
    print(f"Downlaoded file count:{index}")


def main(dwn_file_location, unzip_file_location, will_unzip, api_key, dataset_filetype, total_samples):
    zip_paswd = b'infected'
    headers = {'API-KEY': api_key}
    malwarebazaar_csv_dir = "malwarebazaar_csv/"
    url_download_and_save_zip("https://bazaar.abuse.ch/export/csv/full/", "malwarebazaar_csv.zip")
    extract_zip("malwarebazaar_csv.zip", malwarebazaar_csv_dir)
    malwarebazaar_csv_path = malwarebazaar_csv_dir + "full.csv"
    df_full_csv = skip_first_n_rows_and_import_csv(malwarebazaar_csv_path, 8)
    print_row_counts(df_full_csv)
    download_samples(df_full_csv, dataset_filetype, dwn_file_location, unzip_file_location, will_unzip, headers, zip_paswd, total_samples)


if __name__ == "__main__":
    print("\n----------------------------------\n")
    print("[" + __file__ + "]'s last modified: %s" % time.ctime(os.path.getmtime(__file__)))
    print("\n----------------------------------\n")
    # Check if a parameter is provided
    if len(sys.argv) == 7:
        dwn_file_location = sys.argv[1]
        if not os.path.exists(dwn_file_location):
            os.makedirs(dwn_file_location, exist_ok=True)
        print(f"Zip Files will save:\t{dwn_file_location}")

        unzip_file_location = sys.argv[2]
        if not os.path.exists(unzip_file_location):
            os.makedirs(unzip_file_location, exist_ok=True)
        print(f"Unzip Files will save:\t{unzip_file_location}")

        api_key = sys.argv[3]
        dataset_filetype = sys.argv[4]
        print(f"{dataset_filetype} file type will download")
        will_unzip = sys.argv[5].lower() in ['true', 'yes']
        print(f"Downloaded zip file will be unzip:\t{will_unzip}")
        total_samples = int(sys.argv[6])
        print(f"{total_samples} file will be download")
        print("\n----------------------------------\n")
        main(dwn_file_location, unzip_file_location, will_unzip, api_key, dataset_filetype, total_samples)
    else:
        print("No input directory and output directory provided.")